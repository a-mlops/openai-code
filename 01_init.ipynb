{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@reddyyashu20/llamaindex-create-save-load-indexes-customize-llms-prompts-embeddings-abb581df6dac\n",
    "# https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom chatbot\n",
    "# https://beebom.com/how-train-ai-chatbot-custom-knowledge-base-chatgpt-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llama_index import GPTVectorStoreIndex, download_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf (from -r /Users/alexanderkhachikyan/Desktop/Playground/openai-code/.venv/lib/python3.9/site-packages/llama_index/download/llamahub_modules/requirements.txt (line 1))\n",
      "  Downloading pypdf-3.17.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.3 in ./.venv/lib/python3.9/site-packages (from pypdf->-r /Users/alexanderkhachikyan/Desktop/Playground/openai-code/.venv/lib/python3.9/site-packages/llama_index/download/llamahub_modules/requirements.txt (line 1)) (4.9.0)\n",
      "Downloading pypdf-3.17.2-py3-none-any.whl (277 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.9/277.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-3.17.2\n"
     ]
    }
   ],
   "source": [
    "# https://llamahub.ai/\n",
    "\n",
    "PDFReader = download_loader(\"PDFReader\")\n",
    "\n",
    "loader = PDFReader()\n",
    "documents = loader.load_data(file=Path('./2305.02997.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alexanderkhachikyan/Library/Caches/llama_index.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "index = GPTVectorStoreIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your index to a index.json file\n",
    "index.storage_context.persist(persist_dir=\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import StorageContext, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query engine from the index\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, it is not explicitly mentioned in which case one should not use gradient-boosted decision trees (GBDTs). The context primarily discusses the debate between GBDTs and neural networks (NNs) for tabular data, with some works arguing for GBDTs and others arguing for NNs. However, it does not provide specific scenarios or conditions in which GBDTs should not be used. Therefore, without additional information, it is not possible to determine a specific case in which GBDTs should not be used.\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Type prompt...\")\n",
    "response = query_engine.query(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
